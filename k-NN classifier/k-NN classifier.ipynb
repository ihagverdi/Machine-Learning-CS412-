{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voHKcAfRfdNY"
      },
      "source": [
        "# CS412 - Machine Learning - 2023\n",
        "## Homework 1\n",
        "100 pts\n",
        "\n",
        "## Software: \n",
        "\n",
        "You may find the necessary function references here: \n",
        "\n",
        "http://scikit-learn.org/stable/supervised_learning.html\n",
        "\n",
        "When you search for KNeighborsClassifier for instance, you should find the relevant function and explained parameters, easily.\n",
        "\n",
        "## Submission: \n",
        "Fill this notebook. Write the report section at the end, removing the part in italics. \n",
        "\n",
        "You should prepare a separate pdf document as your homework (name HW1-CS412-yourname.pdf) which consists of the report (Part 8) of the notebook for easy viewing -and- include a link to your notebook from within the pdf report (make sure to include the link obtained from the **Share** button on top right)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YOYiWvHbNDW"
      },
      "source": [
        "##1) Initialize\n",
        "\n",
        "*   First make a copy of the notebook given to you as a starter.\n",
        "\n",
        "*   Make sure you click the Connect button from upper right.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(412)\n",
        "np.random.seed(412)"
      ],
      "metadata": {
        "id": "UIjLyYzJvant"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM-wwHR8qL0M"
      },
      "source": [
        "## 2) Load training dataset\n",
        "\n",
        "*  Read MNIST dataset from Keras library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsX8gEbCUqPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9597ec-d5cf-41c0-c299-e49e209b9e1e"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, Y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) Reshape the MNIST data\n",
        "\n",
        "  In order to use images as input data for the sklearn k-NN classifier, the 2D image arrays need to be reshaped into a 1D arrays (in other words, a feature vector)."
      ],
      "metadata": {
        "id": "jykF6CFioiSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before reshaping: ', X_train.shape, X_test.shape)\n",
        "# print(X_train)"
      ],
      "metadata": {
        "id": "LAX4AsLWrGam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e9ed02-0117-4684-e599-10f99ca63d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before reshaping:  (60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_train, height, width = X_train.shape\n",
        "\n",
        "X_train = np.reshape(X_train, (N_train, height*width)) # from array of shape N_train x 28 x 28 ---> N_train x 784 (Note: 28*28 = 784)\n",
        "X_test = np.reshape(X_test, (len(X_test), height*width)) # from array of shape N_test x 28 x 28 ---> N_test x 784 \n"
      ],
      "metadata": {
        "id": "SEqkxBe5ohf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('After reshaping: ', X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "Zob6_DCBqSHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c09633d-796e-4b1f-f5dc-affbefa7d440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After reshaping:  (60000, 784) (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vop4rwZVxh9Z"
      },
      "source": [
        "##4) Shuffle and Split TRAINING data as train (also called development) (80%) and validation (20%) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEhk8R24xhdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6883db19-97cc-4021-b62f-0525ebfc235c"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Shuffle the training data\n",
        "X_train, Y_train = shuffle(X_train,Y_train,random_state=99)\n",
        "# Split %80 train - 20% val\n",
        "X_development, X_validation, Y_development, Y_validation = train_test_split(X_train,Y_train,test_size=0.2,train_size=0.8,shuffle=False)\n",
        "print(f\"Development data size: {len(X_development)}\\nValidation data size: {len(X_validation)}\\nDevelopment label data size: {len(Y_development)}\\nValidation label data size: {len(Y_validation)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Development data size: 48000\n",
            "Validation data size: 12000\n",
            "Development label data size: 48000\n",
            "Validation label data size: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1oMsPu0AV_"
      },
      "source": [
        "##5) Train k-NN  classifier on development data and do model selection using the validation data\n",
        "\n",
        "\n",
        "* Train a k-NN classifier (use the values specified in the homework PDF file, do not try other values) with the rest of the parameters set to default. \n",
        "\n",
        "* The aim in this homework is not necessarily obtaining the best performance, but to establish the ML pipeline (train a few models, select based on validation set, test, report).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv6oac-T3Wy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186599d3-8d7f-4348-cdcf-b90413080efc"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "k_values = [1,3,5,7,9,11,13]   # <--- Fill the list with the values for n_neighbors\n",
        "\n",
        "best_acc = -1 \n",
        "best_k = None\n",
        "val_accs = []\n",
        "for k in k_values:\n",
        "  # 1) initialize a k-NN classifier with n_neighbors parameter set to k\n",
        "  kNN = KNeighborsClassifier(n_neighbors=k)\n",
        "  # 2) train the classifier using training set\n",
        "  kNN.fit(X_development,Y_development)\n",
        "  # 3) get the predictions of the classifier on the validation set\n",
        "  y_pred = kNN.predict(X_validation) \n",
        "  # 4) compute the accuracy of the predictions on the validation set and append it to val_accs list\n",
        "  score = accuracy_score(y_true=Y_validation,y_pred=y_pred)\n",
        "  val_accs.append(score)\n",
        "  if best_k == None or score>best_acc:\n",
        "    best_k = k\n",
        "    best_acc = score\n",
        "    \n",
        "  print('Validation accuracy for k=', k, ' :', score)\n",
        "  # if validation accuracy is better than best_acc, update best_acc and best_k\n",
        "print('Best validation accuracy (', max(val_accs), ') is achieved with k =', best_k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy for k= 1  : 0.97325\n",
            "Validation accuracy for k= 3  : 0.9735\n",
            "Validation accuracy for k= 5  : 0.9713333333333334\n",
            "Validation accuracy for k= 7  : 0.9691666666666666\n",
            "Validation accuracy for k= 9  : 0.9673333333333334\n",
            "Validation accuracy for k= 11  : 0.9670833333333333\n",
            "Validation accuracy for k= 13  : 0.9650833333333333\n",
            "Best validation accuracy ( 0.9735 ) is achieved with k = 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Plot the obtained validation accuracies versus k values "
      ],
      "metadata": {
        "id": "DQ-0AmI3eqVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(k_values, val_accs)\n",
        "plt.xticks(k_values)\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L4P-dYSoeo3y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d7af39f1-f977-469f-ee5a-0e92ec37049f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boqe46St1--f"
      },
      "source": [
        "## 7) Test your classifier on test set\n",
        "\n",
        "- Now that you have the best value for the ***n_neighbors*** parameter, train a model **with best parameters that you have found according to your validation results**. But now, train the model by combining the training and validation sets. Then report the accuracy on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLke8jyFGng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5c4be1-d8c9-4fba-e45e-7b41fe92d0e4"
      },
      "source": [
        "# 1) initialize a k-NN classifier with n_neighbors parameter set to best_k\n",
        "KNN = KNeighborsClassifier(n_neighbors= best_k)\n",
        "# 2) combine the training and validation sets (you may want to look up numpy.concatenate function for this)\n",
        "x_train = np.concatenate((X_development, X_validation))\n",
        "y_train = np.concatenate((Y_development, Y_validation))\n",
        "# 3) train the classifier using this set\n",
        "KNN.fit(x_train,y_train)\n",
        "# 4) get the predictions of the classifier on the test set\n",
        "KNN_pred = KNN.predict(X_test)  \n",
        "# 5) compute the accuracy of the predictions on the test set\n",
        "KNN_accuracy = accuracy_score(y_true=y_test,y_pred=KNN_pred)\n",
        "print('Test accuracy for k =', best_k, ' :', KNN_accuracy)\n",
        "\n",
        "\n",
        "# Report your result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for k = 3  : 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG3473I9dGE8"
      },
      "source": [
        "##8) Report your results\n",
        "\n",
        "**Notebook should be RUN:** As training and testing may take a long time, we may just look at your notebook results; so make sure **each cell is run**, so outputs are there.\n",
        "\n",
        "**Report:** Write an **one page summary** of your approach to this problem **below**; this should be like an abstract of a paper or the executive summary (you aim for clarity and passing on information, not going to details about known facts such as what kNN is or what MNIST is, assuming they are known to people in your research area). \n",
        "\n",
        "The aim of this report is to explain the steps taken to solve the first assignment of the Machine Learning course. The problem definiton is to implement a machine learning model which can predict (preferably with low error rate) a given sample from the MNIST dataset. For this purpose, we are going to train a k-NN classifier and optimize its performance by finding an optimal value for the nearest neighbors (I.e. k) parameter with the help of Scikit-learn library. First of all, MNIST dataset provides us with 60,000 training data and 10,000 test data. To find the optimal nearest neighbors parameter, we should split the training data into two portions: development data and validation data, with respective portions of 80% and 20%. It is noteworthy to mention that, we shuffle the training data beforehand splitting it to prevent our model to be biased towards any specific patterns or sequences in the data. Next, we train models  on the development data with different values for the nearest neighbors parameter from the list: [1, 3, 5, 7, 9, 11, 13]. Then we measure each of their performance on the validation data so to choose the one with the highest accuracy. Below is the table attached depicting the accuracy rate of models trained with different values for the nearest neighbors parameter from the list aforementioned.\n",
        "Nearest Neighbors parameter (K)\tAccuracy of the model on the validation dataset (percentage)\n",
        "1 -> 0.97325\n",
        "**3\t-> 0.9735**\n",
        "5\t-> 0.9713\n",
        "7\t-> 0.9691\n",
        "9\t-> 0.9673\n",
        "11 -> 0.967\n",
        "13 -> 0.965\n",
        "As highlighted on the table, the nearest neighbors parameter with the value of 3 showed the highest performance on the validation dataset with the accuracy of 97.35%. For this reason, we select the value 3 for the nearest neighbors parameter and train our new model on the full training dataset (i.e. development and validation data combined) which gives us the accuracy of 97.05% on the test data.\n",
        "#Hagverdi Ibrahimli\n",
        "#00030014\n"
      ]
    }
  ]
}